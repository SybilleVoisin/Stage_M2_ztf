{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2300f0b2-128c-478e-9966-099a46e8801a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 10:20:26.168510: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profilage démarré dans /pbs/home/s/svoisin/stage_m2/tmp/jax_moffat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 10:20:33.997413: W external/xla/xla/service/gpu/nvptx_compiler.cc:718] The NVIDIA driver's CUDA version is 12.2 which is older than the ptxas CUDA version (12.4.131). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exécution de fit_adam terminée.\n",
      "Exécution de fit_tncg terminée.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/message_lite.cc:449] tensorflow.profiler.XSpace exceeded maximum protobuf size of 2GB: 4567007552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profilage arrêté.\n"
     ]
    }
   ],
   "source": [
    "import ztfimg\n",
    "from ztfimg import catalog as catalog\n",
    "import ztfin2p3\n",
    "from ztfin2p3 import catalog\n",
    "import pandas\n",
    "import numpy as np\n",
    "import jax\n",
    "import optax\n",
    "import jax.numpy as jnp\n",
    "from jax.scipy import stats as jstats\n",
    "from jax import vmap\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.modeling.models import Moffat2D\n",
    "import jax.profiler as jprof\n",
    "import os\n",
    "from IPython.display import display, HTML\n",
    "from IPython import get_ipython\n",
    "import time\n",
    "\n",
    "# Définir le répertoire pour les fichiers de trace\n",
    "trace_dir = '/pbs/home/s/svoisin/stage_m2/tmp/jax_moffat'\n",
    "os.makedirs(trace_dir, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    # Démarrer la trace\n",
    "    jprof.start_trace(trace_dir, create_perfetto_link=False)\n",
    "    print(f\"Profilage démarré dans {trace_dir}\")\n",
    "\n",
    "\n",
    "    # importing image\n",
    "    liste_file = [\"/sps/ztf/data/sci/2020/0924/431759/ztf_20200924431759_000655_zr_c13_o_q3_sciimg.fits\", \"/sps/ztf/data/sci/2020/0924/431759/ztf_20200924431759_000655_zr_c01_o_q1_sciimg.fits\",\n",
    "                 \"/sps/ztf/data/sci/2020/0924//278681/ztf_20200924278681_000682_zg_c01_o_q1_sciimg.fits\", \"/sps/ztf/data/sci/2020/0924/352269/ztf_20200924352269_000650_zr_c06_o_q2_sciimg.fits\",\n",
    "                 \"/sps/ztf/data/sci/2020/0924/509537/ztf_20200924509537_000700_zg_c03_o_q2_sciimg.fits\", \"/sps/ztf/data/sci/2020/0924/431759/ztf_20200924431759_000655_zr_c09_o_q1_sciimg.fits\"]\n",
    "    \n",
    "    img1 = ztfimg.ScienceQuadrant.from_filename(liste_file[0])\n",
    "    \n",
    "    q1 = img1.get_ccd().get_quadrant(1) #selects quadrant 1 \n",
    "    qimg1 = q1.get_data() #converted to numpy array\n",
    "    \n",
    "    # importing data into a pandas.dataframe\n",
    "    qimg1_catalog = ztfin2p3.catalog.get_img_refcatalog(q1, which=\"gaia_dr2\") # selects the data corresponding to the quadrant in the gaia_dr2 catalog\n",
    "    qimg1_catalog['isolated'] = ztfimg.catalog.get_isolated(qimg1_catalog, seplimit=20) #select stars that are 15 arcsec apart and add a Boolean column\n",
    "    qimg_catalog_isolated = qimg1_catalog.loc[qimg1_catalog['isolated'] == True] # we keep only isolated stars (whose Boolean is True)\n",
    "    qimg_catalog_isolated= qimg_catalog_isolated.drop('isolated', axis=1) #supression of isolated column\n",
    "    \n",
    "    # magnitude selection\n",
    "    mag_inf = qimg_catalog_isolated.phot_g_mean_mag > 14 #selects magnitudes above 14\n",
    "    mag_sup = qimg_catalog_isolated.phot_g_mean_mag < 18 #selects magnitudes below 18\n",
    "    qimg_catalog_isolated_mag = qimg_catalog_isolated.loc[mag_inf & mag_sup] #application of the mask on magnitudes\n",
    "    \n",
    "    # location selection\n",
    "    mag_bord_left = qimg_catalog_isolated_mag.x > 15 # removes stars on the left edge of 15 pixels\n",
    "    mag_bord_right = qimg_catalog_isolated_mag.x < (q1.shape[0]-15) # removes stars on the right edge of 15 pixels\n",
    "    mag_bord_top = qimg_catalog_isolated_mag.y > 15 # removes the stars on the top edge by 15 pixels\n",
    "    mag_bord_bottom = qimg_catalog_isolated_mag.y < (q1.shape[1]-15) # removes stars on the bottom edge of 15 pixels\n",
    "    mag_bord_combined = np.logical_and.reduce((mag_bord_left, mag_bord_right, mag_bord_top, mag_bord_bottom)) #edge selection\n",
    "    qimg_catalog_isolated_mag_bord = qimg_catalog_isolated_mag[mag_bord_combined] #application of edge mask\n",
    "    \n",
    "    def get_stamps(dataframe, size=17):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        ----------\n",
    "        dataframe: pandas.dataframe\n",
    "            dataframe of stars's data from Gaia dr2\n",
    "        size: int\n",
    "            stamp size (17,17)\n",
    "    \n",
    "        Returns:\n",
    "        --------\n",
    "        stamps: np.asarray\n",
    "            data of the star image\n",
    "        \"\"\"\n",
    "        stamps = []\n",
    "        for index, df in qimg_catalog_isolated_mag_bord.iterrows():\n",
    "            x0 = int(round(df[\"x\"]))\n",
    "            y0 = int(round(df[\"y\"]))\n",
    "            left = x0 - (size // 2)\n",
    "            top = y0 - (size // 2)\n",
    "            right = left + size\n",
    "            bottom = top + size\n",
    "            stamps.append(qimg1[top:bottom, left:right])\n",
    "        return np.asarray(stamps)\n",
    "    \n",
    "    \n",
    "    def moffat(x, y, x0, y0, A, alpha, gamma):\n",
    "        r_squared = (x - x0)**2 + (y - y0)**2\n",
    "        return A * (1 + (r_squared / gamma**2))**(-alpha)\n",
    "    \n",
    "    \n",
    "    @jax.jit\n",
    "    def get_model(params):\n",
    "        \"\"\"\n",
    "        Returns the Moffat function\n",
    "    \n",
    "        Parameters:\n",
    "        -----------\n",
    "        params: pytree\n",
    "            [x0,y0: (2,N) centroids\n",
    "             a: (N,) amplitudes\n",
    "             b: (N,) backgrounds\n",
    "             gamma: (1,) float\n",
    "             alpha: (1,) float]\n",
    "        \n",
    "        Returns:\n",
    "        -------\n",
    "        model : arraylike\n",
    "            the Moffat function\n",
    "        \"\"\"\n",
    "        mu, A, b, alpha, gamma = params\n",
    "        x0, y0 = mu[:, 0], mu[:, 1]\n",
    "        \n",
    "        vectorized_moffat = vmap(moffat, in_axes=(None, None, 0, 0, 0, None, None)) # to vectorize on centroids\n",
    "        norm = vectorized_moffat(pos[:, 0], pos[:, 1], x0, y0, A, alpha, gamma)\n",
    "        norm_model = norm + b[:, None]\n",
    "        \n",
    "        return norm_model\n",
    "        \n",
    "    @jax.jit\n",
    "    def get_likelihood(params):\n",
    "        \"\"\"\n",
    "        Computes the Chi squared from the selected model \n",
    "    \n",
    "        Parameters:\n",
    "        ----------\n",
    "        params: list\n",
    "            selected model parameters\n",
    "        data: arraylike\n",
    "            images of stars (flattened)\n",
    "        pos: arraylike\n",
    "            The positions (meshgrid) where the model is evaluated.\n",
    "    \n",
    "        Returns:\n",
    "        --------\n",
    "        summ: float\n",
    "            chi squared sum for all stars\n",
    "        \"\"\"\n",
    "        model = get_model(params)\n",
    "        summ = jnp.sum((model - data)**2)\n",
    "        return summ\n",
    "    \n",
    "    \n",
    "    @jax.jit\n",
    "    def get_logprior(params):\n",
    "        \"\"\"\n",
    "        Returns the probability to have gamma and alpha\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        params: list\n",
    "            selected model parameters\n",
    "    \n",
    "        X: arraylike\n",
    "            The X coordinates.\n",
    "    \n",
    "        Y: arraylike\n",
    "            The Y coordinates.\n",
    "        \n",
    "        Returns:\n",
    "        -------\n",
    "        logprior: float\n",
    "            sum of the two sigma probabilities\n",
    "        \"\"\"\n",
    "        mu, A, b, alpha, gamma = params\n",
    "        logprior_alpha = jstats.norm.logpdf(alpha, loc=1.0, scale=0.5) \n",
    "        logprior_gamma = jstats.norm.logpdf(gamma, loc=1.0, scale=0.5) \n",
    "        logprior = logprior_alpha + logprior_gamma\n",
    "        return logprior\n",
    "    \n",
    "    @jax.jit\n",
    "    def get_logprob(params):\n",
    "        \"\"\" \n",
    "        Computes the sum of the gamma and alpha probabilities and the chi squared\n",
    "    \n",
    "        Parameters:\n",
    "        -----------\n",
    "        params: list\n",
    "            selected model parameters\n",
    "        data: arraylike\n",
    "            images of stars (flattened)\n",
    "        pos: arraylike\n",
    "            The positions (meshgrid) where the model is evaluated.\n",
    "    \n",
    "        Returns:\n",
    "        --------\n",
    "        logprob: float\n",
    "            sum of the sigma probabilities and the chi squared\n",
    "        \"\"\"\n",
    "        logprior = -1 * get_logprior(params)  # to minimize\n",
    "        likelihood = get_likelihood(params)\n",
    "        logprob = logprior + likelihood\n",
    "        return logprob\n",
    "    \n",
    "    def fit_tncg(func, init_param, \n",
    "                 niter=10, tol=5e-3, \n",
    "                 lmbda=1e2, \n",
    "                 **kwargs):\n",
    "        \"\"\" Hessian-free second order optimization algorithm\n",
    "    \n",
    "        The following implementation of TN-CG is largely based on\n",
    "        recommendations given in Martens, James (2010, Deep learning via\n",
    "        Hessian-free optimization, Proc. International  Conference on\n",
    "        Machine Learning).\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        func: function\n",
    "            function to minimize. Should return a float.\n",
    "    \n",
    "        init_param: \n",
    "            entry parameter of the input func\n",
    "    \n",
    "        niter: int\n",
    "            maximum number of iterations\n",
    "    \n",
    "        tol: float\n",
    "            targeted func variations below which the iteration will stop\n",
    "    \n",
    "        lmbda: float\n",
    "            lambda parameter of the tncg algorithm. (optstate)\n",
    "    \n",
    "        **kwargs other func entries \n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            - best parameters\n",
    "            - loss (array)\n",
    "    \n",
    "        Example\n",
    "        -------\n",
    "        ```python\n",
    "        import jax\n",
    "        from edris import simulation, minimize\n",
    "        key = jax.random.PRNGKey(1234)\n",
    "        truth, simu = simulation.get_simple_simulation(key, size=1_000)\n",
    "    \n",
    "        def get_total_chi2(param, data):\n",
    "            # model for a line with error on both axes but no intrinsic scatter.\n",
    "            x_model = param[\"x_model\"]\n",
    "            y_model = x_model * param[\"a\"] + param[\"b\"]\n",
    "        \n",
    "            chi2_y = jnp.sum( ((data[\"x_obs\"] - x_model)/data[\"x_err\"])**2 )\n",
    "            chi2_x = jnp.sum( ((data[\"y_obs\"] - y_model)/data[\"y_err\"])**2 )\n",
    "        \n",
    "            return chi2_y + chi2_x\n",
    "    \n",
    "        init_param = {\"a\": 8., \"b\":0., \"x_model\": simu[\"x_obs\"]} # careful, must be float\n",
    "        best_params, loss = minimize.fit_tncg(get_total_chi2, init_param, data=simu)\n",
    "        ```\n",
    "        \n",
    "        \"\"\"\n",
    "        # handle kwargs more easily\n",
    "        func_ = lambda x: func(x, **kwargs)\n",
    "        fg = jax.value_and_grad(func_)\n",
    "        \n",
    "        # - internal function --- #\n",
    "        def hessian_vector_product(g, x, v):\n",
    "            return jax.jvp(g, (x,), (v,))[1]\n",
    "    \n",
    "        def step_tncg(x, optstate):\n",
    "            loss, grads = fg(x)\n",
    "            lmbda = optstate['lmbda']\n",
    "            fvp = lambda v: jax.tree_util.tree_map(lambda d1, d2: d1 + lmbda*d2, hessian_vector_product(jax.grad(func_), x, v), v)\n",
    "            updates, _ = jax.scipy.sparse.linalg.cg(fvp, grads, maxiter=50)\n",
    "            coco = jax.tree_util.tree_reduce(lambda x, y: x+y, jax.tree_util.tree_map(lambda x, y: (-x*y).sum(), grads, updates))\n",
    "            return updates, loss, optstate, coco\n",
    "    \n",
    "        step_tncg = jax.jit( step_tncg )\n",
    "        # ----------------------- #\n",
    "        \n",
    "        x = init_param\n",
    "        optstate = {'lmbda': lmbda}\n",
    "        losses = []\n",
    "    \n",
    "        for i in range(niter):\n",
    "            updates, loss, optstate, coco = step_tncg(x, optstate)\n",
    "            x1 = jax.tree_util.tree_map(lambda x, y: x - y, x, updates)\n",
    "            dloss = func_(x1) - loss\n",
    "            losses.append(loss)\n",
    "            rho = dloss / coco\n",
    "            \n",
    "            if rho < 0.25:\n",
    "                optstate['lmbda'] = optstate['lmbda'] * 1.5\n",
    "            elif rho > 0.75:\n",
    "                optstate['lmbda'] = optstate['lmbda'] * 0.3\n",
    "                \n",
    "            if dloss < 0: # accept the step\n",
    "                x = x1\n",
    "                \n",
    "            if tol is not None and dloss > -tol:\n",
    "                break\n",
    "            \n",
    "        return x, losses\n",
    "    \n",
    "    \n",
    "    def fit_adam(func, init_params,\n",
    "                 learning_rate=5e-3, niter=200, \n",
    "                 tol=1e-3,\n",
    "                 **kwargs):\n",
    "        \"\"\" simple Adam gradient descent using optax.adam\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        func: function\n",
    "            function to minimize. Should return a float.\n",
    "    \n",
    "        learning_rate: float\n",
    "            learning rate of the gradient descent.\n",
    "            (careful, results can be sensitive to this parameter)\n",
    "            \n",
    "        init_param: \n",
    "            entry parameter of the input func\n",
    "    \n",
    "        niter: int\n",
    "            maximum number of iterations\n",
    "    \n",
    "        tol: float\n",
    "            targeted func variations below which the iteration will stop\n",
    "    \n",
    "        **kwargs other func entries \n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            - best parameters\n",
    "            - loss (array)        \n",
    "        \"\"\"\n",
    "        # handle kwargs more easily\n",
    "        func_ = lambda x: func(x, **kwargs)\n",
    "        \n",
    "        # Initialize the adam optimizer\n",
    "        params = init_params\n",
    "        optimizer = optax.adam(learning_rate)\n",
    "        # Obtain the `opt_state` that contains statistics for the optimizer.\n",
    "        opt_state = optimizer.init(params)\n",
    "        \n",
    "        grad_func = jax.jit(jax.grad( func_ )) # get the derivative\n",
    "        \n",
    "        # and do the gradient descent\n",
    "        losses = []\n",
    "        for i in range(niter):\n",
    "            current_grads = grad_func(params)\n",
    "            updates, opt_state = optimizer.update(current_grads, opt_state)\n",
    "            params = optax.apply_updates(params, updates)\n",
    "            losses.append( func_(params) ) # store the loss function\n",
    "            if tol is not None and (i>2 and ((losses[-2] - losses[-1]) < tol)):\n",
    "                break\n",
    "                \n",
    "        return params, losses\n",
    "    \n",
    "    stamps = get_stamps(qimg_catalog_isolated_mag_bord)\n",
    "    coefs = np.sum(stamps, axis=(1,2))\n",
    "    stamps/=coefs[:,None, None]\n",
    "    \n",
    "    nstars = len(stamps)\n",
    "    size= 17\n",
    "    X = jnp.linspace(-size/2, size/2, size)\n",
    "    Y = jnp.linspace(-size/2, size/2, size)\n",
    "    X, Y = jnp.meshgrid(X, Y)\n",
    "    pos = jnp.vstack((X.ravel(), Y.ravel())).T\n",
    "    \n",
    "    # guess\n",
    "    x0 = jnp.zeros((nstars,), dtype=\"float32\")\n",
    "    y0 = jnp.zeros((nstars,), dtype=\"float32\")\n",
    "    mu = jnp.vstack([x0,y0]).T\n",
    "    A = jnp.ones((nstars,), dtype=\"float32\")  \n",
    "    b = jnp.zeros((nstars,), dtype=\"float32\")\n",
    "    alpha = jnp.array(1., dtype=\"float32\")  \n",
    "    gamma = jnp.array(1., dtype=\"float32\") \n",
    "    \n",
    "    data = stamps.reshape(len(stamps), -1)\n",
    "    grad_func = jax.jit(jax.grad(get_logprob)) # get the derivative\n",
    "    \n",
    "    guess = [mu, A, b, alpha, gamma]\n",
    "    \n",
    "    adam_params, adam_loss = fit_adam(get_logprob, guess, learning_rate=1e-4, tol=1e-5, niter=30000)\n",
    "    print(\"Exécution de fit_adam terminée.\")\n",
    "    tncg_params, tncg_loss = fit_tncg(get_logprob, guess, tol=1e-5, niter=50, lmbda=10000)\n",
    "    print(\"Exécution de fit_tncg terminée.\")\n",
    "\n",
    "finally:\n",
    "    try:\n",
    "        # Arrêter la trace et obtenir le chemin du fichier de trace\n",
    "        trace_file = jprof.stop_trace()\n",
    "        print(\"Profilage arrêté.\")\n",
    "\n",
    "        # Assurez-vous que les messages sont affichés\n",
    "        time.sleep(1)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur en arrêtant la trace: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ZTF - zenv11",
   "language": "python",
   "name": "ztf_zenv11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
